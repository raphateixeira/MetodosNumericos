---
title: "Ajuste de Curvas"
subtitle: "M√©todos Num√©ricos"
author: "Prof. Dr. Raphael Teixeira"
date: ""
format: 
  revealjs:
    footer: "UFPA - CAMTUC - FEE  | M√©todos Num√©ricos - Ajuste de Curvas | Prof. Dr. Raphael Teixeira"
    slide-number: true
    transition: fade
editor: visual

---

### üéØ O Problema do Ajuste de Curvas


**Estimar** uma fun√ß√£o que melhor se ajuste a um conjunto de dados:

::::: columns

::: {.column width="15%"}
<br>

| $x$ | $y$ |
|-----|-----|
| 1.0 | 0.5 |
| 2.0 | 2.5 |
| 3.0 | 2.0 |
| 4.0 | 4.0 |
| 5.0 | 3.5 |

:::

::: {.column width="40%"}

<br>
<br>
<br>

```{python}
#| eval: false 
#| echo: true 
#| code-block-id: fonte-grande-codigo
#| highlight-style: github-dark

import numpy as np
¬† 
x = np.array([1.0, 2.0, 3.0, 4.0, 5.0])
y = np.array([0.5, 2.5, 2.0, 4.0, 3.5])
```

:::

::: {.column width="45%"}

<br><br>

```{python}
#| echo: False
#| fig-align: center
#| out-width: "100%"

import numpy as np
import matplotlib.pyplot as plt
plt.rcParams['font.size'] = 16
plt.rcParams['legend.fontsize'] = 16 

# 1. Dados Observados
xm = np.array([2.5, 3.1, 4.5, 5.3, 6.0, 6.9, 8.0])
ym = np.array([2.0, 2.8, 3.5, 4.6, 5.0, 5.2, 6.5])

# 2. C√°lculo do Ajuste Linear (usando polyfit de grau 1)
# Retorna os coeficientes [a1, a0]
theta = np.polyfit(xm, ym, 1) 
a1 = theta[0]
a0 = theta[1]

# 3. Gerar a Reta de Ajuste
y = a0 + a1 * xm 

# 4. Cria√ß√£o do Gr√°fico
plt.figure(figsize=(8, 5))
plt.scatter(xm, ym, color='blue', label='Dados')
plt.plot(xm, y, color='red', linestyle='-', label=f'Modelo: y = {a1:.2f}x + {a0:.2f}')

plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.grid(True)
plt.show()
```

:::
:::::

Pelo padr√£o, busca-se ajustar uma reta $y = f(x) = a_1x + a_0$.


---

### üìà Minimiza√ß√£o quadr√°tica

Considera-se a soma dos erros (res√≠duos) ao quadrado:
$$
E_{\theta} = \sum_{i=1}^{n} [y_i - f(x_i)]^2
$$

Onde:

-   $E_{\theta}$ √© o erro quadr√°tico total.
-   $y_i$ $i$ valor real (observado).
-   $f(x_i)$ √© o valor previsto pela fun√ß√£o de ajuste.

Busca-se ajustar os coeficientes $\theta = [a_1, a_0]^T\;$ de $f(\cdot)\;$ mapa _minimizar_ $E_{\theta}$.

---

### Otimiza√ß√£o: minimizar $E_{\theta}$

Calcular derivadas parciais do erro $E_{\theta}$ e igualar a zero.

$$
\frac{\partial E_{\theta}}{\partial a_k} = 0
$$

Para $a_1$ e $a_0$ em uma reta, temos: 
$$
\begin{align}
\frac{\partial E}{\partial a_0} &= -2 \sum_{i=1}^{n} [y_i - (a_1 x_i + a_0)] = 0 \\
\frac{\partial E}{\partial a_1} &= -2 \sum\_{i=1}^{n} [y_i - (a_1 x_i + a_0)] x_i = 0
\end{align}
$$


---

### Sistema de Equa√ß√µes Normais

A aplica√ß√£o do MMQ leva ao seguinte sistema (para encontrar $a_0$ e $a_1$):

$$
\begin{cases}
n a_0 + (\sum x_i) a_1 = \sum y_i \\
(\sum x_i) a_0 + (\sum x_i^2) a_1 = \sum x_i y_i
\end{cases}
$$

Este $2 \times 2$ pode ser resolvido por Elimina√ß√£o Gaussiana.

Na forma vetorial matricial:

$$\begin{pmatrix} n & \sum x_i \\ \sum x_i & \sum x_i^2 \end{pmatrix}
\begin{pmatrix} a_0 \\ a_1 \end{pmatrix}
=
\begin{pmatrix} \sum y_i \\ \sum x_i y_i \end{pmatrix}$$

---

<!--



### Minimiza√ß√£o

Determinar par√¢metros √≥timos:Calcular derivadas parciais do erro $E$ em rela√ß√£o a cada par√¢metro e igualar a zero.

$$
\frac{\partial E}{\partial a_k} = 0
$$

Onde $a_k$ s√£o os par√¢metros do modelo (ex: $a_0$, $a_1$, ...).

Para $a_0$ e $a_1$ em uma reta, temos: 
$$
\frac{\partial E}{\partial a_0} = -2 \sum_{i=1}^{n} [y_i - (a_0 + a_1 x_i)] = 0
\frac{\partial E}{\partial a_1} = -2 \sum\_{i=1}\^{n} \[y_i - (a_0 + a_1 x_i)\] x_i = 0
$$

---



---

### Dados de exemplo

```{python}
import numpy as np
x = np.array([1.0, 2.0, 3.0, 4.0, 5.0]) 
y = np.array([0.5, 2.5, 2.0, 4.0, 3.5])
```

-->