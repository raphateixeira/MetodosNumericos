---
title: "Ra√≠zes de Equa√ß√µes N√£o Lineares"
subtitle: "M√©todos Num√©ricos I"
author: "Prof. Dr. Raphael Teixeira"
date: ""
format: 
  revealjs:
    footer: "MN02 - Ra√≠zes de Equa√ß√µes N√£o Lineares"
    slide-number: true
editor: visual
---

## üîç O Problema da Determina√ß√£o de Ra√≠zes

### Defini√ß√£o

O objetivo √© encontrar os valores de $x$ que satisfazem a equa√ß√£o $f(x) = 0$.

> Resolver $\text{e}^x = 4 \sin(x)$ equivale a encontrar os zeros de $f(x) = \text{e}^x - 4 \sin(x)$.

### M√©todos Anal√≠ticos vs. Num√©ricos

* **Anal√≠ticos:** Usam f√≥rmulas exatas (ex: F√≥rmula de Bhaskara para quadr√°ticas). Limitados a poucos tipos de fun√ß√µes.
* **Num√©ricos:** Usam itera√ß√µes para encontrar uma **aproxima√ß√£o** da raiz. Essenciais para fun√ß√µes transcendentais ou complexas.

---

## ü™ì M√©todo da Bisse√ß√£o

### Princ√≠pio Fundamental (Teorema de Bolzano)

O m√©todo da Bisse√ß√£o √© um m√©todo de **fechamento (bracketting)**. 

1.  Escolhemos um intervalo $[a, b]$ onde a fun√ß√£o $f(x)$ tem sinais opostos.
    * Isto √©, $f(a) \cdot f(b) < 0$.
2.  A raiz est√° garantidamente no intervalo.
3.  A nova aproxima√ß√£o √© o ponto m√©dio: $r = (a+b)/2$.
4.  O intervalo √© reduzido pela metade em cada itera√ß√£o.

### Vantagens e Desvantagens

| Vantagens | Desvantagens |
| :--- | :--- |
| **Garante a converg√™ncia** (sempre encontra a raiz). | Converg√™ncia **lenta** (linear). |
| F√°cil de implementar. | Requer o conhecimento pr√©vio de um intervalo v√°lido. |

---

## üß™ Estimativa de Erro na Bisse√ß√£o

O erro absoluto ($E_a$) √© dado pela metade do tamanho do novo intervalo:

$$
E_a = \frac{b - a}{2}
$$

Ap√≥s $k$ itera√ß√µes, o erro m√°ximo √©:

$$
E_k \le \frac{b_0 - a_0}{2^k}
$$

Para atingir uma precis√£o ($\epsilon$) desejada, o n√∫mero m√≠nimo de itera√ß√µes ($k$) √©:

$$
k \ge \log_2\left(\frac{b_0 - a_0}{\epsilon}\right)
$$

---

## ‚ö°Ô∏è M√©todo de Newton-Raphson

### F√≥rmula Iterativa

O m√©todo de Newton √© um m√©todo **aberto** que utiliza a reta tangente √† curva no ponto atual $x_i$ para estimar o pr√≥ximo ponto $x_{i+1}$.

$$
x_{i+1} = x_i - \frac{f(x_i)}{f'(x_i)}
$$

* Requer uma aproxima√ß√£o inicial $x_0$.

### Converg√™ncia R√°pida

Quando a aproxima√ß√£o inicial √© pr√≥xima da raiz, o m√©todo converge **quadraticamente**.

$$
\text{Erro}_{i+1} \propto (\text{Erro}_i)^2
$$

---

## ‚ö†Ô∏è Desafios de Newton-Raphson

::: columns
::: {.column width="50%"}
### Problemas Comuns

1.  **Derivada Zero:** Se $f'(x_i) \approx 0$, a f√≥rmula se torna inst√°vel (divis√£o por zero).
2.  **Diverg√™ncia:** Uma aproxima√ß√£o inicial ruim pode fazer a sequ√™ncia de $x_i$ se afastar da raiz.
3.  **Ra√≠zes M√∫ltiplas:** A converg√™ncia se torna mais lenta (linear).
:::

::: {.column width="50%"}

:::
:::

---

## üíª Exemplo em Python

Encontrando a raiz de $f(x) = \text{e}^{-x} - x$.

```python
import numpy as np

def f(x):
    # e^(-x) - x
    return np.exp(-x) - x

def df(x):
    # Derivada: -e^(-x) - 1
    return -np.exp(-x) - 1

def newton_raphson(x0, tol=1e-6, max_iter=10):
    x = x0
    for i in range(max_iter):
        delta_x = f(x) / df(x)
        x_novo = x - delta_x
        
        if abs(x_novo - x) < tol:
            return x_novo
        
        x = x_novo
    return x

# Aproxima√ß√£o inicial
raiz = newton_raphson(x0=1.0) 

print(f"Raiz aproximada: {raiz:.6f}")
# Output deve ser pr√≥ximo de 0.567143